# Awesome Weak-to-Strong Generalization

A curated list of papers related to **weak-to-strong generalization (W2S)** and adjacent topics such as easy‑to‑hard generalization, scalable oversight, and weak supervision for powerful models.

## Papers

*Sorted by year (newest first). Author lists are truncated after three names when long.*

| Year | Title | Authors | Venue |
|------|-------|---------|-------|
| 2025 | [Alice: Proactive Learning with Teacher's Demonstrations for Weak-to-Strong Generalization](https://arxiv.org/abs/2504.07316) | Shujin Wu, Cheng Qian, Yi R. Fung, Paul Pu Liang, Heng Ji | ArXiv |
| 2025 | [Debate Helps Weak-to-Strong Generalization](https://arxiv.org/abs/2501.13124) | Hao Lang, Fei Huang, Yongbin Li | ArXiv |
| 2025 | [Denoising Mutual Knowledge Distillation in Bi-Directional Multiple Instance Learning](https://arxiv.org/abs/2505.12074) | Chen Shu, Boyu Fu, Yiman Li et al. | ArXiv |
| 2025 | [Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension](https://arxiv.org/abs/2502.05075) | Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei | ArXiv |
| 2025 | [Escaping Collapse: The Strength of Weak Data for Large Language Model Training](https://arxiv.org/abs/2502.08924) | Kareem Amin, Sara Babakniya, Alex Bie et al. | ArXiv |
| 2025 | [Hand-crafted feature-guided histologic image classification via weak-to-strong generalization](https://doi.org/10.1117/12.3047492) | Changjie Lu, Zong Fan, Zhimin Wang et al. | ArXiv |
| 2025 | [How to Mitigate Overfitting in Weak-to-strong Generalization?](https://arxiv.org/abs/2503.04249) | Junhao Shi, Qinyuan Cheng, Zhaoye Fei, Y. Zheng, Qipeng Guo, Xipeng Qiu | ArXiv |
| 2025 | [Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society](https://arxiv.org/abs/2504.17404) | Yi Zeng, Feifei Zhao, Yuwei Wang et al. | ArXiv |
| 2025 | [Reducing Uncertainty of Weak Supervised Signals via Mutual Information Techniques](https://doi.org/10.1109/ACCESS.2025.3546605) | Yichen Liu, Hanlin Feng, Xin Zhang | IEEE Access |
| 2025 | [Relating Misfit to Gain in Weak-to-Strong Generalization Beyond the Squared Loss](https://arxiv.org/abs/2501.19105) | Abhijeet Mulgund, Chirag Pabbaraju | ArXiv |
| 2025 | [Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions](https://arxiv.org/abs/2502.00620) | Yihao Xue, Jiping Li, Baharan Mirzasoleiman | ArXiv |
| 2025 | [Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL](https://arxiv.org/abs/2502.11107) | Wei Yao, Wenkai Yang, Ziqiao Wang, Yankai Lin, Yong Liu | ArXiv |
| 2025 | [Scaling Laws For Scalable Oversight](https://arxiv.org/abs/2504.18530) | Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark | ArXiv |
| 2025 | [Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges](https://arxiv.org/abs/2502.01612) | Nayoung Lee, Ziyang Cai, Avi Schwarzschild et al. | ArXiv |
| 2025 | [Strong Empowered and Aligned Weak Mastered Annotation for Weak-to-Strong Generalization](https://doi.org/10.1609/aaai.v39i26.34955) | Yongqi Li, Xin Miao, Mayi Xu, Tieyun Qian | ArXiv |
| 2025 | [Superalignment with Dynamic Human Values](https://arxiv.org/abs/2503.13621) | Florian Mai, David Kacz'er, Nicholas Kluge Corrêa, Lucie Flek | ArXiv |
| 2025 | [Synergistic Weak-Strong Collaboration by Aligning Preferences](https://arxiv.org/abs/2504.15188) | Yizhu Jiao, Xuchao Zhang, Zhaoyang Wang et al. | ArXiv |
| 2025 | [Understanding the Capabilities and Limitations of Weak-to-Strong Generalization](https://arxiv.org/abs/2502.01458) | Wei Yao, Wenkai Yang, Ziqiao Wang, Yankai Lin, Yong Liu | ArXiv |
| 2025 | [Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors](https://arxiv.org/abs/2504.04785) | Fan Nie, Lan Feng, Haotian Ye et al. | ArXiv |
| 2025 | [Weak-to-Strong Generalization Even in Random Feature Networks, Provably](https://arxiv.org/abs/2503.02877) | Marko Medvedev, Kaifeng Lyu, Dingli Yu, Sanjeev Arora, Zhiyuan Li, Nathan Srebro | ArXiv |
| 2024 | [A transfer learning framework for weak to strong generalization](https://arxiv.org/abs/2405.16236) | Seamus Somerstep, Felipe Maia Polo, Moulinath Banerjee et al. | International Conference on Learning Representations |
| 2024 | [Bayesian WeakS-to-Strong from Text Classification to Generation](https://arxiv.org/abs/2406.03199) | Ziyun Cui, Ziyang Zhang, Wen Wu, Guangzhi Sun, Chao Zhang | ArXiv |
| 2024 | [Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts](https://arxiv.org/abs/2402.15505) | Yuejiang Liu, Alexandre Alahi | ArXiv |
| 2024 | [Disentangling Latent Shifts of In-Context Learning Through Self-Training](https://arxiv.org/abs/2410.01508) | Josip Juki'c, Jan Snajder | ArXiv |
| 2024 | [EnsemW2S: Can an Ensemble of LLMs be Leveraged to Obtain a Stronger LLM?](https://arxiv.org/abs/2410.04571) | Aakriti Agrawal, Mucong Ding, Zora Che et al. | ArXiv |
| 2024 | [Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization](https://arxiv.org/abs/2409.07335) | Mehrdad Zakershahrak, Samira Ghodratnama | ArXiv |
| 2024 | [Generalizing Trust: Weak-to-Strong Trustworthiness in Language Models](https://arxiv.org/abs/2501.00418) | Martin Pawelczyk, Lillian Sun, Zhenting Qi, Aounon Kumar, Hima Lakkaraju | ArXiv |
| 2024 | [High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws](https://arxiv.org/abs/2410.18837) | M. E. Ildiz, Halil Alperen Gozeten, Ege Onur Taga, Marco Mondelli, Samet Oymak | ArXiv |
| 2024 | [Improving Weak-to-Strong Generalization with Reliability-Aware Alignment](https://arxiv.org/abs/2406.19032) | Yue Guo, Yi Yang | ArXiv |
| 2024 | [Improving Weak-to-Strong Generalization with Scalable Oversight and Ensemble Learning](https://arxiv.org/abs/2402.00667) | Jitao Sang, Yuhang Wang, Jing Zhang et al. | ArXiv |
| 2024 | [Language Model Preference Evaluation with Multiple Weak Evaluators](https://arxiv.org/abs/2410.12869) | Zhengyu Hu, Jieyu Zhang, Zhihan Xiong et al. | ArXiv |
| 2024 | [MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization](https://arxiv.org/abs/2410.07672) | Yougang Lyu, Lingyong Yan, Zihan Wang et al. | ArXiv |
| 2024 | [Provable Weak-to-Strong Generalization via Benign Overfitting](https://arxiv.org/abs/2410.04638) | David X. Wu, A. Sahai | ArXiv |
| 2024 | [Quantifying the Gain in Weak-to-Strong Generalization](https://arxiv.org/abs/2405.15116) | Moses Charikar, Chirag Pabbaraju, Kirankumar Shiragur | NeurIPS 2024 |
| 2024 | [Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://arxiv.org/abs/2408.16737) | Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi | ArXiv |
| 2024 | [Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization](https://arxiv.org/abs/2406.11431) | Wenkai Yang, Shiqi Shen, Guangyao Shen, Zhi Gong, Yankai Lin | ArXiv |
| 2024 | [Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning](https://arxiv.org/abs/2402.00530) | Ming Li, Yong Zhang, Shwai He et al. | ArXiv |
| 2024 | [Theoretical Analysis of Weak-to-Strong Generalization](https://arxiv.org/abs/2405.16043) | Hunter Lang, David Sontag, Aravindan Vijayaraghavan | NeurIPS 2024 |
| 2024 | [Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models](https://arxiv.org/abs/2402.03749) | Jianyuan Guo, Hanting Chen, Chengcheng Wang, Kai Han, Chang Xu, Yunhe Wang | ArXiv |
| 2024 | [Weak-to-Strong Generalization Through the Data-Centric Lens](https://arxiv.org/abs/2412.03881) | Changho Shin, John Cooper, Frederic Sala | ICLR 2025 |
| 2024 | [Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning](https://arxiv.org/abs/2410.12621) | Ruimeng Ye, Yang Xiao, Bo Hui | ArXiv |
| 2024 | [Weak-to-Strong Jailbreaking on Large Language Models](https://arxiv.org/abs/2401.17256) | Xuandong Zhao, Xianjun Yang, Tianyu Pang et al. | ArXiv |
| 2024 | [Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model](https://arxiv.org/abs/2410.18640) | Wenhong Zhu, Zhiwei He, Xiaofeng Wang, Pengfei Liu, Rui Wang | ArXiv |
| 2024 | [Weak-to-Strong Reasoning](https://arxiv.org/abs/2407.13647) | Yuqing Yang, Yan Ma, Pengfei Liu | ArXiv |
| 2024 | [Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models](https://arxiv.org/abs/2405.19262) | Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, Yu Qiao | ArXiv |
| 2024 | [What is the Role of Small Models in the LLM Era: A Survey](https://arxiv.org/abs/2409.06857) | Lihu Chen, G. Varoquaux | ArXiv |
| 2024 | [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org/abs/2409.08813) | Leitian Tao, Yixuan Li | ArXiv |
| 2024 | [Zero-to-Strong Generalization: Eliciting Strong Capabilities of Large Language Models Iteratively without Gold Labels](https://arxiv.org/abs/2409.12425) | Chaoqun Liu, Qin Chao, Wenxuan Zhang et al. | ArXiv |
| 2023 | [On student-teacher deviations in distillation: does it pay to disobey?](https://arxiv.org/abs/2301.12923) | Vaishnavh Nagarajan, A. Menon, Srinadh Bhojanapalli, H. Mobahi, Surinder Kumar | ArXiv |
| 2023 | [Understanding Self-Distillation in the Presence of Label Noise](https://arxiv.org/abs/2301.13304) | Rudrajit Das, Sujay Sanghavi | ArXiv |
| 2023 | [Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision](https://arxiv.org/abs/2312.09390) | Collin Burns, Pavel Izmailov, J. Kirchner et al. | ICML 2024 |
---

### Contributing

Spotted an incorrect venue or missing paper? Please open a pull request with the fix. Include the BibTeX or official proceedings link whenever possible.

### License

CC‑BY‑SA‑4.0
